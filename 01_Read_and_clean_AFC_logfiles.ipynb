{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an analysis function whose purpose is to read and arrange the LogFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Importation of modules and functions from python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the module \"os\" whose purpose is to dialogue with the OS\n",
    "import os\n",
    "# The function os.listdir makes a list of what is inside 'log_files'\n",
    "print(os.listdir(\"log_files\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Setting the path to the logfile we are to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same function as before, we make a list of what is inside the student's file. This is only an example, and it uses the path to the files in MY computer, you'll have to put your own path if you want it to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the *example_directory*, which is the directory that contains all the logfiles we want to analyse.\n",
    "\n",
    "<span style=\"text-decoration: underline\">Tip</span>: In order to find the path to the logfiles, I recommend unzipping all the files and putting them in three different directories (ex: L1, L2, L3). Once you open the jupyter notebook from the directory which contains the three L1/2/3 directories using a terminal, you can find the path to your documents easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_directory = \"log_files/L1/Sarah Moreira_1365881_assignsubmission_file_/logFiles (Sarah Moreira)/logFiles (Sarah Moreira)/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the __os.listdir__ function to see what documents are contained in the *example_directory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(example_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can only analyse AFC files with the following functions, we set the path *file_ex* and *file_ex2* as the example_directory + the path to an AFC file (2AFC/5AFC). We found this paths with the previous __os.listdir__  function, which made a list of the files contained in the *example_directory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ex = example_directory + \"2AFC_a_Wed_Feb_17_10_18_00_2021.log\"\n",
    "file_ex2 = example_directory + \"5AFC_1_Sat_Feb_27_09_53_53_2021.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Opening and reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function __open__ to open the file and read it (\"r\"). Then, we retrieve the lines and close the file. \n",
    "The function __print__ in the middle is only here for aesthetic purposes, to make it easier to differenciate the treatment of *file_ex* and *file_ex2*. \"print(\"\")\" will print a blank line, while \"print(\"______\")\" will display a line in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(file_ex, 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "print(file_ex)\n",
    "print(\"\")\n",
    "print(lines)\n",
    "print(\"_______________________________________________________________________________________________\")\n",
    "print(\"\")\n",
    "\n",
    "f = open(file_ex2, 'r')\n",
    "lines2 = f.readlines()\n",
    "f.close()\n",
    "print(file_ex2)\n",
    "print(\"\")\n",
    "print(lines2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Cleaning the lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting rid of the tabulations and line breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the previous cell, there are \"\\t\" and \"\\n\" when we print the lines. \"\\t\" means that there is a space between two items, the \"\\n\" means that there is a line break. These should not be visible, so we want to delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new loop variable called \"i\", and we say that \n",
    "# for \"i\" is the range of the the length (=len) of the \n",
    "# lines that we retrieved earlier, all the line breaks (\\n)\n",
    "# will we replaced by a space (\"\").\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = lines[i].replace(\"\\n\", \"\")\n",
    "# We recall the path to the file with print(file_ex)\n",
    "print(file_ex)\n",
    "# Blank line\n",
    "print(\" \")\n",
    "# After this, we display (=print) the lines of file_ex\n",
    "print(lines)\n",
    "print(\"_______________________________________________________________________________________________\")\n",
    "print(\"\")\n",
    "# We do the same for file_ex2\n",
    "for i in range(len(lines2)):\n",
    "    lines2[i] = lines2[i].replace(\"\\n\", \"\")\n",
    "print(file_ex2)\n",
    "print(\" \")\n",
    "print(lines2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split the lines according to the tabulations \"\\t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new empty list called \"attributes\".\n",
    "# It is empty since there is nothing inside the brackets.\n",
    "# This means that we will add items later.\n",
    "attributes = []\n",
    "# For the variable \"l\" in the lines we have retrieved\n",
    "for l in lines:\n",
    "    # We add the splitted lines (=l.split) and we add them\n",
    "    # to the list \"attributes\" (=attributes.append)\n",
    "    attributes.append(l.split('\\t'))\n",
    "# We do the same for the second exercise.\n",
    "attributes2 = []\n",
    "for l in lines2:\n",
    "    attributes2.append(l.split('\\t'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Combining the previous functions and creating a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import numpy and we will refer to it as \"np\".\n",
    "import numpy as np\n",
    "\n",
    "# We define a new function called get_lines.\n",
    "def get_lines(path):\n",
    "    # We open the file called file_ex, and we read it (='r')\n",
    "    f = open(file_ex, 'r')\n",
    "    # The \"lines\" are the ones that we have retrieved and read.\n",
    "    lines = f.readlines()\n",
    "    # We close the document\n",
    "    f.close()\n",
    "    # and return the lines\n",
    "    return lines\n",
    "\n",
    "# Next, we create a dictionary. The function takes one\n",
    "# attribute: the pathe to the exercise.\n",
    "def create_dico(path):\n",
    "    # We take the lines that were returned in the\n",
    "    # previous function called get_lines\n",
    "    lines = get_lines(path)\n",
    "    # We create a new loop variable called \"i\", and we say that \n",
    "    # for \"i\" is the range of the the length (=len) of the \n",
    "    # lines that we retrieved earlier, all the line breaks (\\n)\n",
    "    # will we replaced by a space (\"\").\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].replace(\"\\n\", \"\")\n",
    "    # We create a new empty list called \"attributes\".\n",
    "    # It is empty since there is nothing inside the brackets.\n",
    "    # This means that we will add items later.\n",
    "    attributes = []\n",
    "    # For the variable \"l\" in the lines we have retrieved\n",
    "    for l in lines:\n",
    "        # We add the splitted lines (=l.split) and we add them\n",
    "        # to the list \"attributes\" (=attributes.append)\n",
    "        attributes.append(l.split('\\t'))\n",
    "    # We assign the first line (0) to the date    \n",
    "    date = attributes[0]\n",
    "    # The keys to the second (1)\n",
    "    keys = attributes[1]\n",
    "    # The statistics of the exercise to the penultimate line (-1)\n",
    "    stats_total = attributes[-1]\n",
    "    # The interesting data is in the middle\n",
    "    # from the third line (2) to the antepenultimate\n",
    "    data = attributes[2:-1]\n",
    "    # We delete the empty lines if the length of \n",
    "    # the data (=len(data[i])) is equal to 1.\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]) == 1:\n",
    "            del data[i]\n",
    "    # The numeric data is:\n",
    "    numeric = ['Response Time', 'NbErreurs', 'Repetitions']\n",
    "    # We create a new empty dictionary \n",
    "    dico = {}\n",
    "    # We skim through all the lines in data\n",
    "    for line in data:\n",
    "        # For the variable \"i\" and \"key\" in the \n",
    "        # group of keys (keys = attributs[1])\n",
    "        for i, key in enumerate(keys):\n",
    "            # If it is the first time we encounter\n",
    "            # this key (= key not in dico.keys())\n",
    "            if key not in dico.keys():\n",
    "                # then we create a new dictionary\n",
    "                # especially for this new key\n",
    "                dico[key] = []\n",
    "            # if the key is in the list \"numeric\"\n",
    "            # (numeric = ['Response Time', 'NbErreurs', 'Repetitions'])\n",
    "            if key in numeric:\n",
    "                # then we add (=append) the values\n",
    "                # to the dictionary\n",
    "                dico[key].append(float(line[i]))\n",
    "            # Otherwise, (=else)\n",
    "            else:\n",
    "                # if we have already encountered this key\n",
    "                # we add the values to the dictionary\n",
    "                # that has already been created.\n",
    "                dico[key].append(line[i])\n",
    "    dico[\"date\"] = date\n",
    "    # For key in the dictionary of keys\n",
    "    for key in dico.keys():\n",
    "        # We make an np.array, a table\n",
    "        # of all the values in the dico\n",
    "        dico[key] = np.array(dico[key])\n",
    "    # We return the dictionary\n",
    "    return dico\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display a dictionary for *file_ex*.\n",
    "\n",
    "For all the keys in the file (Sound File, Stimulus, Vowel, Response Time, NbErreurs, Repetitions, and date), we have the related values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dico(file_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for *file_ex2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dico(file_ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
