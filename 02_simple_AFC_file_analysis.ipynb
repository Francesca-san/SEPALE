{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of an AFC file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyse the data of a single AFC exercice, whether it is a 5AFC or a 2AFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Importation of modules and functions from python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import python modules\n",
    "# numpy : a mathematical function that is very useful!\n",
    "import numpy as np\n",
    "# Pyplot : very important tool if you want to create plots!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# From the module utils we import the function create_dico\n",
    "# which is helpful if you want to manage files\n",
    "from utils import create_dico\n",
    "\n",
    "# From the module analysis we import all (*)\n",
    "from analysis import *\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Setting the path to the logfile we are to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing modules and functions, we determine a directory called *example_directory*. In this cell, the path of the file from my computer is used, you'll need to put the logfiles in a special directory, find the path to these logfiles and paste it in quotation marks. The __os.listdir__ function will simply make a list of the files you have in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dina Joy Rellier_1374034_assignsubmission_file_',\n",
       " 'Lobna Fawal_1550137_assignsubmission_file_',\n",
       " 'Kimshi De Sa_1374018_assignsubmission_file_',\n",
       " 'Selena Bougonier_1550142_assignsubmission_file_',\n",
       " 'Sarah Azzi_1365654_assignsubmission_file_',\n",
       " 'Louanne Guennec_1365638_assignsubmission_file_',\n",
       " 'Annalena Geisler_1365653_assignsubmission_file_',\n",
       " 'Maxellende Delmas_1374047_assignsubmission_file_',\n",
       " 'Camille Babet_1374053_assignsubmission_file_',\n",
       " 'Aurelie Ngia_1374036_assignsubmission_file_',\n",
       " 'Emelina Vanhooland_1398746_assignsubmission_file_',\n",
       " 'Dylem Rouabhi_1374064_assignsubmission_file_',\n",
       " 'Benjy Michelet_1374009_assignsubmission_file_',\n",
       " 'Smahen Horma_1365656_assignsubmission_file_',\n",
       " 'JOHANNA STAUDENMANN_1398738_assignsubmission_file_',\n",
       " 'Shanice Abdou_1398752_assignsubmission_file_',\n",
       " 'Lydia Deghi',\n",
       " 'Lou Guillen_1374068_assignsubmission_file_',\n",
       " 'Habib Messaouer_1374056_assignsubmission_file_',\n",
       " 'Lucas Amsellem_1374017_assignsubmission_file_',\n",
       " 'Sarah Sefraoui_1365627_assignsubmission_file_',\n",
       " 'Sianna Rahme_1398742_assignsubmission_file_',\n",
       " 'Zoe Collado_1365634_assignsubmission_file_',\n",
       " 'Lauryne Barnay Theodore_1374033_assignsubmission_file_',\n",
       " 'Paul Bigard',\n",
       " 'Alexandra Meneault_1365624_assignsubmission_file_',\n",
       " 'Mathilde Aguera_1374046_assignsubmission_file_',\n",
       " 'Saba Sattar_1374026_assignsubmission_file_',\n",
       " 'Nadia Hafsa_1398740_assignsubmission_file_',\n",
       " 'Mathilde Rivain_1374040_assignsubmission_file_',\n",
       " 'Lea Da Silva_1398744_assignsubmission_file_',\n",
       " 'Khouloud Bali_1374031_assignsubmission_file_',\n",
       " 'Louise Thomassery_1398755_assignsubmission_file_',\n",
       " 'Eglantine Meriau_1398754_assignsubmission_file_',\n",
       " 'Jessika Sivaradjalingam_1374020_assignsubmission_file_',\n",
       " 'Chloe Bargilliat_1365663_assignsubmission_file_',\n",
       " 'Dan Fellous_1365651_assignsubmission_file_',\n",
       " 'Lena Glize_1374067_assignsubmission_file_',\n",
       " 'Julia Malefant_1365630_assignsubmission_file_',\n",
       " 'Lara Karacan_1398739_assignsubmission_file_',\n",
       " 'Alexia Aliberto_1365650_assignsubmission_file_',\n",
       " 'Camille Pillet_1365661_assignsubmission_file_',\n",
       " 'Kellelah Coudre_1374006_assignsubmission_file_',\n",
       " 'Louise Kania_1398747_assignsubmission_file_',\n",
       " 'Anais Chazelas_1365635_assignsubmission_file_',\n",
       " 'Juliette Baude_1374066_assignsubmission_file_',\n",
       " 'Monia Teffah_1398745_assignsubmission_file_',\n",
       " 'Deborah Oukaci_1374049_assignsubmission_file_',\n",
       " 'Mahdia Mouhali_1550135_assignsubmission_file_',\n",
       " 'Melanie Colin_1398753_assignsubmission_file_',\n",
       " 'Marion Bourtayre_1365648_assignsubmission_file_',\n",
       " 'Narimen Melki_1374048_assignsubmission_file_',\n",
       " 'Anurag Das',\n",
       " 'Eliana Collens Gaspard_1550134_assignsubmission_file_',\n",
       " 'Alice Halimi_1374060_assignsubmission_file_',\n",
       " 'Deborah Bourgeois_1365632_assignsubmission_file_',\n",
       " 'Eleonore Henry_1550132_assignsubmission_file_',\n",
       " 'Sharleen Mc Aleavy_1374022_assignsubmission_file_']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "example_directory = \"log_files/L3/\"\n",
    "os.listdir(example_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5AFC_1_Thu_May_06_22_53_49_2021.log',\n",
       " '2AFC_a_Thu_May_06_22_48_04_2021.log',\n",
       " 'AX_av_Wed_Mar_31_23_19_41_2021.log',\n",
       " 'AX_av_Sat_Mar_20_17_36_44_2021.log',\n",
       " '2AFC_a_Mon_Feb_22_19_44_12_2021.log',\n",
       " '2AFC_a_Sat_Apr_17_16_05_00_2021.log',\n",
       " '2AFC_av_Sat_Apr_17_16_07_09_2021.log',\n",
       " 'AX_a_Sat_Mar_20_17_39_19_2021.log',\n",
       " 'AX_av_Sat_Apr_17_15_56_38_2021.log',\n",
       " '2AFC_i_Sat_Mar_20_17_46_00_2021.log',\n",
       " 'AX_av_Sat_Mar_13_18_40_58_2021.log',\n",
       " '5AFC_2_Sat_Mar_20_17_50_12_2021.log',\n",
       " '5AFC_2_Tue_Mar_02_22_50_57_2021.log',\n",
       " '5AFC_1_Wed_Mar_31_23_32_40_2021.log',\n",
       " 'AX_av_Tue_Mar_02_22_35_27_2021.log',\n",
       " '2AFC_a_Sat_Mar_13_18_47_14_2021.log',\n",
       " '2AFC_a_Tue_May_04_19_28_07_2021.log',\n",
       " '2AFC_av_Tue_May_04_19_29_58_2021.log',\n",
       " '2AFC_av_Tue_Mar_02_22_42_24_2021.log',\n",
       " 'AX_a_Mon_Feb_22_19_35_06_2021.log',\n",
       " '2AFC_i_Wed_Mar_10_01_33_38_2021.log',\n",
       " '2AFC_i_Wed_Mar_31_23_30_29_2021.log',\n",
       " 'AX_a_Sat_Mar_13_18_44_09_2021.log',\n",
       " '5AFC_2_Thu_May_06_22_55_42_2021.log',\n",
       " 'AX_a_Tue_May_04_19_25_17_2021.log',\n",
       " '2AFC_av_Wed_Mar_10_01_31_43_2021.log',\n",
       " '2AFC_a_Wed_Mar_31_23_26_37_2021.log',\n",
       " '5AFC_1_Wed_Mar_10_01_35_54_2021.log',\n",
       " '5AFC_2_Sat_Apr_17_16_14_50_2021.log',\n",
       " 'AX_a_Sat_Apr_17_16_02_14_2021.log',\n",
       " 'ListeOddity_1_00.txt',\n",
       " '5AFC_1_Mon_Feb_22_19_47_25_2021.log',\n",
       " 'AX_i_Thu_May_06_22_40_13_2021.log',\n",
       " '2AFC_i_Sat_Mar_13_18_52_29_2021.log',\n",
       " '5AFC_2_Tue_May_04_19_35_51_2021.log',\n",
       " 'AX_a_Wed_Mar_10_01_27_01_2021.log',\n",
       " '2AFC_i_Tue_May_04_19_31_40_2021.log',\n",
       " '5AFC_2_Wed_Mar_31_23_34_40_2021.log',\n",
       " '2AFC_a_Tue_Mar_02_22_40_30_2021.log',\n",
       " '5AFC_2_Sat_Mar_20_17_53_28_2021.log',\n",
       " 'AX_i_Sat_Mar_13_18_38_03_2021.log',\n",
       " 'AX_a_Sat_Apr_17_15_59_26_2021.log',\n",
       " 'ListeOddity_2_00.txt',\n",
       " 'AX_i_Tue_Mar_02_22_32_53_2021.log',\n",
       " 'AX_i_Wed_Mar_10_01_21_50_2021.log',\n",
       " 'AX_av_Mon_Feb_22_19_37_37_2021.log',\n",
       " 'AX_a_Tue_Mar_02_22_37_57_2021.log',\n",
       " 'AX_i_Tue_May_04_19_20_31_2021.log',\n",
       " '5AFC_2_Sat_Mar_13_18_57_19_2021.log',\n",
       " 'AX_i_Mon_Feb_22_19_29_02_2021.log',\n",
       " 'AX_i_Sat_Apr_17_15_53_43_2021.log',\n",
       " '5AFC_1_Sat_Apr_17_16_12_36_2021.log',\n",
       " '2AFC_a_Wed_Mar_10_01_29_29_2021.log',\n",
       " '2AFC_a_Sat_Mar_20_17_42_09_2021.log',\n",
       " '5AFC_1_Sat_Mar_13_18_54_57_2021.log',\n",
       " 'AX_a_Thu_May_06_22_45_51_2021.log',\n",
       " 'AX_i_Sat_Mar_20_17_34_03_2021.log',\n",
       " 'AX_a_Wed_Mar_31_23_21_49_2021.log',\n",
       " '2AFC_av_Wed_Mar_31_23_28_47_2021.log',\n",
       " '2AFC_av_Thu_May_06_22_49_46_2021.log',\n",
       " '5AFC_1_Tue_May_04_19_33_55_2021.log',\n",
       " '2AFC_av_Sat_Mar_13_18_50_14_2021.log',\n",
       " '2AFC_i_Tue_Mar_02_22_44_13_2021.log',\n",
       " '2AFC_i_Sat_Apr_17_16_10_16_2021.log',\n",
       " '2AFC_i_Thu_May_06_22_51_35_2021.log',\n",
       " 'AX_av_Tue_May_04_19_23_06_2021.log',\n",
       " '5AFC_1_Sat_Mar_20_17_47_57_2021.log',\n",
       " 'AX_av_Wed_Mar_10_01_24_25_2021.log',\n",
       " 'AX_av_Thu_May_06_22_42_46_2021.log',\n",
       " '5AFC_2_Wed_Mar_10_01_38_06_2021.log',\n",
       " '5AFC_1_Tue_Mar_02_22_46_26_2021.log',\n",
       " 'AX_i_Wed_Mar_31_23_17_07_2021.log',\n",
       " '2AFC_av_Sat_Mar_20_17_44_16_2021.log']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#example_directory = \"log_files/L3/\"\n",
    "example_directory2 = \"log_files/L3/Selena Bougonier_1550142_assignsubmission_file_/logFiles/logFiles\"\n",
    "# The function listdir makes a list of \n",
    "# all the files in example_directory\n",
    "\n",
    "os.listdir(example_directory2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __os.listdir__ function enables you to choose out of the list of files, the logfile that you want to analyse. After having determined the directory (the *example_directory*) you'll have to choose the path of the file you want to look more closely into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the directory of a random student, you can change it if you want. To do so, you'll have to change the path by the path to another student's directory, and place it in quotation marks as we did before. \n",
    "The *example_file* is the *example_directory*, plus the path to the logfile you want to analyse. This logfile can be AFC, AX, or Oddity, although these functions only work for AFC files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the directory of a random student, you can change it\n",
    "example_directory = \"log_files/L1/Cassandra Amaro Ribeiro_1365824_assignsubmission_file_/logFiles/logFiles\"\n",
    "# example_file = example_directory + \"/5AFC_2_Sat_Jan_30_22_11_07_2021.log\"\n",
    "example_file = example_directory + \"/2AFC_i_Thu_Mar_18_17_22_34_2021.log\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Creation of a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary called *file_dico*, which will \"remember\", in a way, the different keys of the *example_file*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a dictionary for the example_file\n",
    "file_dico = create_dico(example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want you can print the keys for this exercice. To do so, you'll have to use the function __print__ and put in parentheses what you'd like to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Sound File', 'Stimulus', 'Vowel', 'Response Time', 'NbErreurs', 'Repetitions', 'date'])\n"
     ]
    }
   ],
   "source": [
    "print(file_dico.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Analysis of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vowel/stimuli with one or more errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function __with_errors__ that is in the module analysis, you can choose to show the vowels for which the student made mistakes. You can do the same for the stimuli, you'll just have to indicate that the key is \"Stimulus\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably noticed that there is an attribute to the function, called *at_least*. Here, it is equal to 1, but you can also see the vowels/stimuli for which the student made more than one mistake by replacing the 1 by 2/3 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'i', 'I', 'I', 'i', 'i']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_errors(file_dico, key=\"Vowel\", at_least=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Count of errors per vowel/stimuli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell counts the number of mistakes per stimuli/vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deed': 0,\n",
       " 'peak': 1,\n",
       " 'bik': 0,\n",
       " 'min': 1,\n",
       " 'pick': 0,\n",
       " 'did': 0,\n",
       " 'keep': 0,\n",
       " 'leak': 1,\n",
       " 'teak': 1,\n",
       " 'bin': 0,\n",
       " 'tick': 1,\n",
       " 'kip': 1,\n",
       " 'mean': 0,\n",
       " 'cheap': 0,\n",
       " 'lick': 0,\n",
       " 'bean': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_errors(file_dico, key=\"Stimulus\", count_one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Vowel/stimuli with no errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell makes a list of the vowels/stimuli for which the student did not make a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'i',\n",
       " 'I',\n",
       " 'I',\n",
       " 'i',\n",
       " 'I',\n",
       " 'i',\n",
       " 'I',\n",
       " 'I',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'I',\n",
       " 'i',\n",
       " 'i',\n",
       " 'I']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_no_errors(file_dico, key=\"Vowel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. List of the vowels/stimuli for which the student made a mistake or repeated the sound file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have what was to become the function __criteria_by_key__: combining two elements of the *file_dico*, we print, we make a list of the *key* (a.k.a. \"s\") and a correspondant *criteria* (a.k.a. \"e\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deed 0.0\n",
      "peak 1.0\n",
      "bik 0.0\n",
      "min 1.0\n",
      "pick 0.0\n",
      "did 0.0\n",
      "min 0.0\n",
      "deed 0.0\n",
      "keep 0.0\n",
      "leak 0.0\n",
      "teak 1.0\n",
      "leak 1.0\n",
      "keep 0.0\n",
      "bin 0.0\n",
      "tick 1.0\n",
      "kip 1.0\n",
      "mean 0.0\n",
      "peak 0.0\n",
      "bik 0.0\n",
      "deed 0.0\n",
      "did 0.0\n",
      "keep 0.0\n",
      "cheap 0.0\n",
      "lick 0.0\n",
      "tick 0.0\n",
      "did 0.0\n",
      "bean 0.0\n",
      "tick 0.0\n",
      "tick 0.0\n",
      "bean 0.0\n"
     ]
    }
   ],
   "source": [
    "for s, e in zip(file_dico[\"Stimulus\"], file_dico[\"NbErreurs\"]):\n",
    "    print(s, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sum of criterias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function __np.sum__, you can sum the number of repetitions, of errors, and even the response time. You only have to write the right labels, *Repetitions*, *NbErrors*, *Response Time*, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(file_dico['Repetitions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we use the function __count_with_criteria__ (you can change the key and the criteria), and the tool __stat_exo__ which basically makes a simple table of the sum of wrong and right answers, and response time. Feel free, for this last function, to change the key by *Stimulus*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 20.099112033843994, 'i': 21.82487964630127}\n",
      "key | errors | right | mean resp time\n",
      "--------------------\n",
      "I   |  3.0   | 12 | 20.099112033843994\n",
      "i   |  3.0   | 12 | 21.82487964630127\n"
     ]
    }
   ],
   "source": [
    "# Sum of repetitions\n",
    "print(count_with_criteria(file_dico, key=\"Vowel\", criteria='Response Time'))\n",
    "stat = exo_stat(example_file, 'Vowel')\n",
    "print_stat_exo(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
