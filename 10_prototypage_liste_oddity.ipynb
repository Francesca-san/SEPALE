{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We import python modules\n",
    "# numpy : a mathematical function that is very useful!\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# We define a new class called \"Exo\"\n",
    "class Exo:\n",
    "    '''\n",
    "    This is a description of the class, \n",
    "    If you have any problem with it\n",
    "    you can always write help(Exo)\n",
    "    '''\n",
    "    # This is the initializing function of any exercise\n",
    "    # It has only one argument, called \"path\"\n",
    "    def __init__(self, path):\n",
    "        # Here we define the shared attributes of all the exercises\n",
    "        # They all have a path\n",
    "        self.path = path\n",
    "        # We can find several numeric keys in those exercises: \n",
    "        # Response time, number of mistakes, and repetitions\n",
    "        self.numeric_keys = ['Response Time', 'NbErreurs', 'Repetitions']\n",
    "        # All the exercises have lines that \n",
    "        # have to be taken, cleansed, and parsed\n",
    "        self.get_lines()\n",
    "        self.clean_lines()\n",
    "        self.parse_lines()\n",
    "        \n",
    "    # Here we take the function get_lines that \n",
    "    # can be used on any AFC exercise. It gets the \n",
    "    # lines of the files and reads them, hence 'r'.\n",
    "    def get_lines(self):\n",
    "        f = open(self.path, 'r')\n",
    "        # We take the lines\n",
    "        self.lines = f.readlines()\n",
    "        # We close the file\n",
    "        f.close()\n",
    "        \n",
    "    # This function cleans the lines of the files\n",
    "    def clean_lines(self):\n",
    "        # We remove the \\n that are then replaced\n",
    "        # by a space. \\n are line breaks.\n",
    "        for i in range(len(self.lines)):\n",
    "            self.lines[i] = self.lines[i].replace(\"\\n\", \"\")\n",
    "        # If the line is empty, we delete it\n",
    "        # We maka a list which contains all the \n",
    "        # empty lines (= to_delete.append(i))\n",
    "        to_delete = []\n",
    "        for i in range(len(self.lines)):\n",
    "            if len(self.lines[i]) == 0:\n",
    "                to_delete.append(i)\n",
    "        # then we delete (del) what has been\n",
    "        # added in to_delete\n",
    "        for i in to_delete:\n",
    "            del self.lines[i]   \n",
    "        \n",
    "    # We parse the lines so as to assign attributes to lines    \n",
    "    def parse_lines(self):\n",
    "        attributs = []\n",
    "        # We separate lines according to the tabulation\n",
    "        for l in self.lines:\n",
    "            attributs.append(l.split('\\t'))\n",
    "        # The date is the first line -> 0\n",
    "        self.date = attributs[0]\n",
    "        # The keys are the second line --> 1\n",
    "        self.keys = np.array(attributs[1])\n",
    "        # The data is to be found from the third\n",
    "        # line (2) to the penultimate (-1)\n",
    "        data = attributs[2:-1]\n",
    "        # The last line is the number of mistakes\n",
    "        # and repetitions --> stats_total\n",
    "        self.stats_total = attributs[-1]\n",
    "        columns = []\n",
    "        for j, k in enumerate(self.keys):\n",
    "            if k in self.numeric_keys:\n",
    "                columns.append(np.array([float(data[i][j]) for i in range(len(data))]))\n",
    "            else:\n",
    "                columns.append(np.array([data[i][j] for i in range(len(data))]))\n",
    "        # We have defined the content of the columns, now we have \n",
    "        # to indicate that it belongs to class Exo, hence 'self'\n",
    "        self.columns = columns\n",
    "        # Pour ne pas perdre ses clés !\n",
    "        self.key_to_index = {}\n",
    "        for i, k in enumerate(self.keys):\n",
    "            self.key_to_index[k] = i\n",
    "        \n",
    "    def display(self):\n",
    "        # on parcours les keys\n",
    "        for i in range(self.keys.shape[0]):\n",
    "            print(f'{self.keys[i]} {self.columns[i]}')\n",
    "\n",
    "    \n",
    "    def criteria_by_key(self, key, criteria, zeros=False):\n",
    "        if key not in self.keys:\n",
    "            raise Exception('Key not in my keys !')\n",
    "        if criteria not in self.keys:\n",
    "            raise Exception('Criteria not in my keys !')\n",
    "        #labels, values = exo.criteria_by_key(key, criteria)\n",
    "        # We retrieve the index number of the key/column\n",
    "        k_index = self.key_to_index[key]\n",
    "        # We retrieve the index number of the criteria/column\n",
    "        c_index = self.key_to_index[criteria]\n",
    "        # We retrieve the columns\n",
    "        key_column = self.columns[k_index]\n",
    "        criteria_column = self.columns[c_index]\n",
    "        dico = {}\n",
    "        # For each key, we keep aside its \n",
    "        # value and we count the number of \n",
    "        # times we come across it.\n",
    "        # dico[key] -> [valeur_critère, compteur d'occurences]\n",
    "        for i, k in enumerate(key_column):\n",
    "            value = criteria_column[i]\n",
    "            if k not in dico.keys():\n",
    "                dico[k] = [value, 1]\n",
    "            else:\n",
    "                dico[k] = [dico[k][0] + value, dico[k][1] + 1]\n",
    "        # We return the dictionary\n",
    "        return dico\n",
    "    \n",
    "        \n",
    "# We define a specific type of exercise: the 2AFC\n",
    "class AFC2(Exo):\n",
    "    '''\n",
    "    This is a description of the class, \n",
    "    If you have any problem with it\n",
    "    you can always write help(AFC2)\n",
    "    '''\n",
    "    # This is a specific attribute of AFC2 which lists \n",
    "    # the keys that contain numeric quantities\n",
    "    \n",
    "    # This is the initializing function of the exercise\n",
    "    # It has only one argument, called \"path\"\n",
    "    def __init__(self, path):\n",
    "        # Here, we define the attributes that are shared\n",
    "        # by the AFC2 exercises, they all have a path\n",
    "        super().__init__(path)\n",
    "\n",
    "        \n",
    "# We define a specific type of exercise: the 5AFC\n",
    "class AFC5(Exo):\n",
    "    '''\n",
    "    This is a description of the class, \n",
    "    If you have any problem with it\n",
    "    you can always write help(AFC5)\n",
    "    '''\n",
    "    # This is the initializing function of the exercise\n",
    "    # It has only one argument, called \"path\"\n",
    "    def __init__(self, path):\n",
    "        # Here, we define the attributes that are shared\n",
    "        # by the AFC2 exercises, they all have a path\n",
    "        super().__init__(path)\n",
    "        \n",
    "# We define a new class called \"AX\"\n",
    "class AX(Exo):\n",
    "    '''\n",
    "    This is a description of the class, \n",
    "    If you have any problem with it\n",
    "    you can always write help(AX)\n",
    "    '''\n",
    "    # This is the initializing function of any exercise\n",
    "    # It has only one argument, called \"path\"\n",
    "    def __init__(self, path):\n",
    "        # Here we define the shared attributes of all the exercises\n",
    "        # They all have a path\n",
    "        super().__init__(path)\n",
    "        \n",
    "        \n",
    "    def parse_lines(self):\n",
    "        attributs = []\n",
    "        # We separate lines according to the tabulation\n",
    "        for l in self.lines:\n",
    "            attributs.append(l.split('\\t'))\n",
    "        # The date is the first line -> 0\n",
    "        date = attributs[0]\n",
    "        # The keys are the second line --> 1\n",
    "        self.keys = np.array(['Sound File', 'Stimulus','Response Time', 'NbErreurs', 'Repetitions'])\n",
    "        # The data is to be found from the third\n",
    "        # line (2) to the antepenultimate (-2) (empty line at end)\n",
    "        data_tmp = attributs[2:-2]\n",
    "        data = []\n",
    "        for l in data_tmp:\n",
    "            # splitting soudfile string\n",
    "            sf = l[0]\n",
    "            splitted = sf.split('-')\n",
    "            sleft = splitted[0].split('_')\n",
    "            sright = splitted[1].split('_')\n",
    "            vs = sleft[1] + \" vs \" + sright[1]\n",
    "            # to only count some columns\n",
    "            data.append([sf, vs, l[4], l[5], l[6]])\n",
    "        # The last line is the number of mistakes\n",
    "        # and repetitions --> stats_total\n",
    "        stats_total = attributs[-1]\n",
    "        columns = []\n",
    "        for j, k in enumerate(self.keys):\n",
    "            if k in self.numeric_keys:\n",
    "                columns.append(np.array([float(data[i][j]) for i in range(len(data))]))\n",
    "            else:\n",
    "                columns.append(np.array([data[i][j] for i in range(len(data))]))\n",
    "        self.columns = columns\n",
    "        # Pour ne pas perdre ses clés !\n",
    "        self.key_to_index = {}\n",
    "        for i, k in enumerate(self.keys):\n",
    "            self.key_to_index[k] = i\n",
    "            \n",
    "\n",
    "# We define a new class called \"Oddity\"\n",
    "class Oddity(Exo):\n",
    "    '''\n",
    "    This is a description of the class, \n",
    "    If you have any problem with it\n",
    "    you can always write help(Oddity)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        # Here we define the shared attributes of all the exercises\n",
    "        # They all have a path\n",
    "        super().__init__(path)\n",
    "        \n",
    "    def parse_lines(self):\n",
    "        attributs = []\n",
    "        # We separate lines according to the tabulation\n",
    "        for l in self.lines:\n",
    "            attributs.append(l.split('\\t'))\n",
    "        # The date is the first line -> 0\n",
    "        date = attributs[0]\n",
    "        # The keys are the second line --> 1\n",
    "        self.keys = np.array(['Sound File', 'Stimulus','Response Time', 'NbErreurs', 'Repetitions'])\n",
    "        # The data is to be found from the third\n",
    "        # line (2) to the antepenultimate (-2) (empty line at end)\n",
    "        data_tmp = attributs[2:-2]\n",
    "        data = []\n",
    "        for l in data_tmp:\n",
    "            # splitting soudfile string\n",
    "            sf = l[0]\n",
    "            #re.split = ('-|, _', sf)\n",
    "            #sleft = re.split[0]\n",
    "            #smiddle = re.split[1]\n",
    "            #sright = re.split[2]\n",
    "            #vs = sleft[1] + \" vs \" + smiddle [1] + \" vs \" + sright[0]\n",
    "            splitted = sf.split('-')\n",
    "            sleft = splitted[0].split('_')\n",
    "            smiddle = splitted[1].split('_')\n",
    "            sright = splitted[2].split('_')\n",
    "            vs = sleft[1] + \" vs \" + smiddle [1] + \" vs \" + sright[1]\n",
    "            #print(vs)\n",
    "            # do not take care of the three\n",
    "            # following columns\n",
    "            data.append([sf, vs, l[5], l[6], l[7]])\n",
    "        # The last line is the number of mistakes\n",
    "        # and repetitions --> stats_total\n",
    "        stats_total = attributs[-1]\n",
    "        columns = []\n",
    "        for j, k in enumerate(self.keys):\n",
    "            if k in self.numeric_keys:\n",
    "                columns.append(np.array([float(data[i][j]) for i in range(len(data))]))\n",
    "            else:\n",
    "                columns.append(np.array([data[i][j] for i in range(len(data))]))\n",
    "        self.columns = columns\n",
    "        #print(data)\n",
    "        # Pour ne pas perdre ses clés !\n",
    "        self.key_to_index = {}\n",
    "        for i, k in enumerate(self.keys):\n",
    "            self.key_to_index[k] = i\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AX_a_Wed_Jan_27_19_41_38_2021.log', 'ListeOddity_1_00.txt', 'AX_i_Wed_Jan_27_19_32_57_2021.log', '5AFC_2_Wed_Jan_27_22_14_29_2021.log', 'ListeOddity_2_00.txt', '2AFC_av_Wed_Jan_27_21_16_15_2021.log', 'AX_av_Wed_Jan_27_19_45_11_2021.log', '2AFC_a_Wed_Jan_27_20_58_59_2021.log', '5AFC_1_Wed_Jan_27_21_54_03_2021.log', '2AFC_i_Wed_Jan_27_21_36_10_2021.log']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"log_files/L1/Enzo Mazni_1365880_assignsubmission_file_/logFiles/logFiles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_directory = \"log_files/L1/Enzo Mazni_1365880_assignsubmission_file_/logFiles/logFiles/\"\n",
    "example_file = example_directory + \"ListeOddity_2_00.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a_lack_H06-a_lack_H05-v_puck_H09', 'lack vs lack vs puck', '0.5075971229962306', '0', '1'], ['I_seek_H08-I_seek_H07-i_sick_H05', 'seek vs seek vs sick', '0.3936197099974379', '2', '2'], ['i_sick_H08-i_sick_H09-I_seek_H06', 'sick vs sick vs seek', '1.3428415399976075', '0', '0'], ['a_ban_H09-v_bun_H06-v_bun_H07', 'ban vs bun vs bun', '0.05106296400481369', '3', '6'], ['I_peak_H04-i_pick_H09-I_peak_H06', 'peak vs pick vs peak', '0.8797577900113538', '2', '2'], ['A_park_H05-A_park_H04-v_puck_H08', 'park vs park vs puck', '0.4542828580015339', '0', '1'], ['i_sick_H04-I_seek_H05-i_sick_H09', 'sick vs seek vs sick', '1.066715586988721', '0', '4'], ['v_tut_F05-a_tat_F08-v_tut_F06', 'tut vs tat vs tut', '0.07443403299839702', '3', '6'], ['I_seek_F09-i_sick_F08-i_sick_F06', 'seek vs sick vs sick', '0.05039456899976358', '0', '1'], ['a_cat_F04-v_cut_F08-a_cat_F07', 'cat vs cut vs cat', '0.051316814991878346', '0', '2'], ['a_ban_F09-v_bun_F06-v_bun_F07', 'ban vs bun vs bun', '0.4561837799992645', '0', '1'], ['A_tart_F06-A_tart_F09-v_tut_F07', 'tart vs tart vs tut', '0.40946092299418524', '0', '2'], ['v_bun_H05-v_bun_H07-a_ban_H08', 'bun vs bun vs ban', '0.4676782899914542', '0', '2'], ['i_tick_H08-i_tick_H05-I_teak_H04', 'tick vs tick vs teak', '0.4238431709964061', '0', '1'], ['A_barn_H07-v_bun_H06-A_barn_H05', 'barn vs bun vs barn', '0.6611717599880649', '2', '4'], ['v_tut_F05-A_tart_F08-A_tart_F06', 'tut vs tart vs tart', '0.805842586007202', '0', '0'], ['v_bun_F09-v_bun_F04-A_barn_F08', 'bun vs bun vs barn', '0.45978961800574325', '0', '3'], ['A_park_H07-v_puck_H09-v_puck_H05', 'park vs puck vs puck', '0.5003232400049455', '0', '1'], ['i_sick_F09-I_seek_F08-I_seek_F07', 'sick vs seek vs seek', '0.589526173993363', '0', '0'], ['A_tart_F08-v_tut_F04-A_tart_F05', 'tart vs tut vs tart', '0.46052902600786183', '0', '1'], ['a_ban_F06-v_bun_F04-a_ban_F08', 'ban vs bun vs ban', '0.4775216230045771', '0', '2'], ['A_card_H05-v_cud_H06-A_card_H07', 'card vs cud vs card', '1.0463924590003444', '2', '2'], ['i_kip_F07-I_keep_F04-i_kip_F06', 'kip vs keep vs kip', '0.4341486659977818', '0', '2'], ['i_pick_F09-I_peak_F08-i_pick_F07', 'pick vs peak vs pick', '0.7987983269995311', '0', '7'], ['I_keep_F06-i_kip_F07-I_keep_F05', 'keep vs kip vs keep', '0.4231683809921378', '0', '1'], ['v_cut_H04-v_cut_H05-A_cart_H09', 'cut vs cut vs cart', '0.7415118950011674', '0', '2'], ['i_sick_F08-i_sick_F09-I_seek_F06', 'sick vs sick vs seek', '0.5927828620042419', '0', '0'], ['A_cart_H06-v_cut_H04-A_cart_H09', 'cart vs cut vs cart', '0.8369504220027011', '0', '1'], ['v_puck_H09-A_park_H05-v_puck_H07', 'puck vs park vs puck', '0.5768833239999367', '0', '8']]\n"
     ]
    }
   ],
   "source": [
    "ex_exo = Oddity(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lack vs lack vs puck': [1.0, 1],\n",
       " 'seek vs seek vs sick': [2.0, 1],\n",
       " 'sick vs sick vs seek': [0.0, 2],\n",
       " 'ban vs bun vs bun': [7.0, 2],\n",
       " 'peak vs pick vs peak': [2.0, 1],\n",
       " 'park vs park vs puck': [1.0, 1],\n",
       " 'sick vs seek vs sick': [4.0, 1],\n",
       " 'tut vs tat vs tut': [6.0, 1],\n",
       " 'seek vs sick vs sick': [1.0, 1],\n",
       " 'cat vs cut vs cat': [2.0, 1],\n",
       " 'tart vs tart vs tut': [2.0, 1],\n",
       " 'bun vs bun vs ban': [2.0, 1],\n",
       " 'tick vs tick vs teak': [1.0, 1],\n",
       " 'barn vs bun vs barn': [4.0, 1],\n",
       " 'tut vs tart vs tart': [0.0, 1],\n",
       " 'bun vs bun vs barn': [3.0, 1],\n",
       " 'park vs puck vs puck': [1.0, 1],\n",
       " 'sick vs seek vs seek': [0.0, 1],\n",
       " 'tart vs tut vs tart': [1.0, 1],\n",
       " 'ban vs bun vs ban': [2.0, 1],\n",
       " 'card vs cud vs card': [2.0, 1],\n",
       " 'kip vs keep vs kip': [2.0, 1],\n",
       " 'pick vs peak vs pick': [7.0, 1],\n",
       " 'keep vs kip vs keep': [1.0, 1],\n",
       " 'cut vs cut vs cart': [2.0, 1],\n",
       " 'cart vs cut vs cart': [1.0, 1],\n",
       " 'puck vs park vs puck': [8.0, 1]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_exo.criteria_by_key(\"Stimulus\", \"Repetitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
